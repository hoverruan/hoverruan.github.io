<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>在阿里云上安装 Kubernetes v1.25.4 | HoverR&#39;s Blog</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="本次测试安装最新的发布版本 v1.25.4。比较大的改动是从 v1.24 开始正式 移除了对dockershim的支持，本文使用 containerd &#43; nerdctl 来替代原来的 docker。
之前操作系统都选择 CentOS 7.x，但是 7.x 的维护期也只是到2024年6月30日就结束了。后续的服务器操作系统打算切换到阿里云自己维护的 Alibaba Cloud Linux 上面，本次测试采用的服务器版本是 Alibaba Cloud Linux 3.2104。
本次测试采取在墙外制作系统镜像、在墙内使用的策略，避免配置其他第三方的安装源：
创建一台香港的ECS服务器 安装必要的系统软件 拉取 Kubernetes 集群所需的镜像 制作成阿里云的系统自定义镜像 将镜像复制到国内的区域 在国内区域基于上述镜像，配置 Kubernetes 集群 制作自定义镜像 基本思路：
通过 nerdctl 的 full distribution 发行版本，完成 runc、containerd、CNI plugins 等重要组件的安装，大大简化了安装过程 对 containerd 的配置改动： 默认的 sandbox_image 是 k8s.gcr.io/pause:3.6，改成跟 kubeadm config images pull 获取的版本一致：registry.k8s.io/pause:3.8 通过 systemd 来启动 执行 yum install 时指定具体的版本号，减少不确定性 采用 calico 作为网络插件 通过下面的脚本，可以一键安装好所需的全部工具并拉取所有的镜像：
#!/usr/bin/env bash sudo setenforce 0 sudo sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config swapoff -a cat &lt;&lt;EOF | sudo tee /etc/modules-load.">
    <meta name="generator" content="Hugo 0.107.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="在阿里云上安装 Kubernetes v1.25.4" />
<meta property="og:description" content="本次测试安装最新的发布版本 v1.25.4。比较大的改动是从 v1.24 开始正式 移除了对dockershim的支持，本文使用 containerd &#43; nerdctl 来替代原来的 docker。
之前操作系统都选择 CentOS 7.x，但是 7.x 的维护期也只是到2024年6月30日就结束了。后续的服务器操作系统打算切换到阿里云自己维护的 Alibaba Cloud Linux 上面，本次测试采用的服务器版本是 Alibaba Cloud Linux 3.2104。
本次测试采取在墙外制作系统镜像、在墙内使用的策略，避免配置其他第三方的安装源：
创建一台香港的ECS服务器 安装必要的系统软件 拉取 Kubernetes 集群所需的镜像 制作成阿里云的系统自定义镜像 将镜像复制到国内的区域 在国内区域基于上述镜像，配置 Kubernetes 集群 制作自定义镜像 基本思路：
通过 nerdctl 的 full distribution 发行版本，完成 runc、containerd、CNI plugins 等重要组件的安装，大大简化了安装过程 对 containerd 的配置改动： 默认的 sandbox_image 是 k8s.gcr.io/pause:3.6，改成跟 kubeadm config images pull 获取的版本一致：registry.k8s.io/pause:3.8 通过 systemd 来启动 执行 yum install 时指定具体的版本号，减少不确定性 采用 calico 作为网络插件 通过下面的脚本，可以一键安装好所需的全部工具并拉取所有的镜像：
#!/usr/bin/env bash sudo setenforce 0 sudo sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config swapoff -a cat &lt;&lt;EOF | sudo tee /etc/modules-load." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hoverruan.me/posts/install-kubernetes-v1.25.4-on-aliyun/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-26T22:30:37+08:00" />
<meta property="article:modified_time" content="2022-11-26T22:30:37+08:00" />

<meta itemprop="name" content="在阿里云上安装 Kubernetes v1.25.4">
<meta itemprop="description" content="本次测试安装最新的发布版本 v1.25.4。比较大的改动是从 v1.24 开始正式 移除了对dockershim的支持，本文使用 containerd &#43; nerdctl 来替代原来的 docker。
之前操作系统都选择 CentOS 7.x，但是 7.x 的维护期也只是到2024年6月30日就结束了。后续的服务器操作系统打算切换到阿里云自己维护的 Alibaba Cloud Linux 上面，本次测试采用的服务器版本是 Alibaba Cloud Linux 3.2104。
本次测试采取在墙外制作系统镜像、在墙内使用的策略，避免配置其他第三方的安装源：
创建一台香港的ECS服务器 安装必要的系统软件 拉取 Kubernetes 集群所需的镜像 制作成阿里云的系统自定义镜像 将镜像复制到国内的区域 在国内区域基于上述镜像，配置 Kubernetes 集群 制作自定义镜像 基本思路：
通过 nerdctl 的 full distribution 发行版本，完成 runc、containerd、CNI plugins 等重要组件的安装，大大简化了安装过程 对 containerd 的配置改动： 默认的 sandbox_image 是 k8s.gcr.io/pause:3.6，改成跟 kubeadm config images pull 获取的版本一致：registry.k8s.io/pause:3.8 通过 systemd 来启动 执行 yum install 时指定具体的版本号，减少不确定性 采用 calico 作为网络插件 通过下面的脚本，可以一键安装好所需的全部工具并拉取所有的镜像：
#!/usr/bin/env bash sudo setenforce 0 sudo sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config swapoff -a cat &lt;&lt;EOF | sudo tee /etc/modules-load."><meta itemprop="datePublished" content="2022-11-26T22:30:37+08:00" />
<meta itemprop="dateModified" content="2022-11-26T22:30:37+08:00" />
<meta itemprop="wordCount" content="513">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="在阿里云上安装 Kubernetes v1.25.4"/>
<meta name="twitter:description" content="本次测试安装最新的发布版本 v1.25.4。比较大的改动是从 v1.24 开始正式 移除了对dockershim的支持，本文使用 containerd &#43; nerdctl 来替代原来的 docker。
之前操作系统都选择 CentOS 7.x，但是 7.x 的维护期也只是到2024年6月30日就结束了。后续的服务器操作系统打算切换到阿里云自己维护的 Alibaba Cloud Linux 上面，本次测试采用的服务器版本是 Alibaba Cloud Linux 3.2104。
本次测试采取在墙外制作系统镜像、在墙内使用的策略，避免配置其他第三方的安装源：
创建一台香港的ECS服务器 安装必要的系统软件 拉取 Kubernetes 集群所需的镜像 制作成阿里云的系统自定义镜像 将镜像复制到国内的区域 在国内区域基于上述镜像，配置 Kubernetes 集群 制作自定义镜像 基本思路：
通过 nerdctl 的 full distribution 发行版本，完成 runc、containerd、CNI plugins 等重要组件的安装，大大简化了安装过程 对 containerd 的配置改动： 默认的 sandbox_image 是 k8s.gcr.io/pause:3.6，改成跟 kubeadm config images pull 获取的版本一致：registry.k8s.io/pause:3.8 通过 systemd 来启动 执行 yum install 时指定具体的版本号，减少不确定性 采用 calico 作为网络插件 通过下面的脚本，可以一键安装好所需的全部工具并拉取所有的镜像：
#!/usr/bin/env bash sudo setenforce 0 sudo sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config swapoff -a cat &lt;&lt;EOF | sudo tee /etc/modules-load."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        HoverR&#39;s Blog
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">在阿里云上安装 Kubernetes v1.25.4</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-11-26T22:30:37+08:00">November 26, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>本次测试安装最新的发布版本 v1.25.4。比较大的改动是从 v1.24 开始正式 <a href="https://kubernetes.io/blog/2022/01/07/kubernetes-is-moving-on-from-dockershim/">移除了对dockershim的支持</a>，本文使用 <a href="https://github.com/containerd/containerd">containerd</a> + <a href="https://github.com/containerd/nerdctl">nerdctl</a> 来替代原来的 docker。</p>
<p>之前操作系统都选择 CentOS 7.x，但是 7.x 的维护期也只是到2024年6月30日就结束了。后续的服务器操作系统打算切换到阿里云自己维护的 <code>Alibaba Cloud Linux</code> 上面，本次测试采用的服务器版本是 <code>Alibaba Cloud Linux 3.2104</code>。</p>
<p>本次测试采取在墙外制作系统镜像、在墙内使用的策略，避免配置其他第三方的安装源：</p>
<ul>
<li>创建一台香港的ECS服务器
<ul>
<li>安装必要的系统软件</li>
<li>拉取 Kubernetes 集群所需的镜像</li>
<li>制作成阿里云的系统自定义镜像</li>
</ul>
</li>
<li>将镜像复制到国内的区域</li>
<li>在国内区域基于上述镜像，配置 Kubernetes 集群</li>
</ul>
<h2 id="制作自定义镜像">制作自定义镜像</h2>
<p>基本思路：</p>
<ul>
<li>通过 nerdctl 的 <a href="https://github.com/containerd/nerdctl/releases">full distribution 发行版本</a>，完成 <code>runc</code>、<code>containerd</code>、<code>CNI plugins</code> 等重要组件的安装，大大简化了安装过程
<ul>
<li>对 <code>containerd</code> 的配置改动：
<ul>
<li>默认的 <code>sandbox_image</code> 是 <code>k8s.gcr.io/pause:3.6</code>，改成跟 <code>kubeadm config images pull</code> 获取的版本一致：<code>registry.k8s.io/pause:3.8</code></li>
<li>通过 <code>systemd</code> 来启动</li>
</ul>
</li>
</ul>
</li>
<li>执行 <code>yum install</code> 时指定具体的版本号，减少不确定性</li>
<li>采用 <code>calico</code> 作为网络插件</li>
</ul>
<p>通过下面的脚本，可以一键安装好所需的全部工具并拉取所有的镜像：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>sudo setenforce <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>sudo sed -i <span style="color:#e6db74">&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>modprobe overlay
</span></span><span style="display:flex;"><span>modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/containerd/nerdctl/releases/download/v1.0.0/nerdctl-full-1.0.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>tar Cxzvvf /usr/local nerdctl-full-1.0.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>containerd config default &gt; /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s#k8s.gcr.io/pause:3.6#registry.k8s.io/pause:3.8#g&#39;</span> /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/SystemdCgroup = false/SystemdCgroup = true/g&#39;</span> /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl daemon-reload
</span></span><span style="display:flex;"><span>systemctl enable --now containerd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">exclude=kubelet kubeadm kubectl
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install -y kubelet-1.25.4-0 kubeadm-1.25.4-0 kubectl-1.25.4-0 --disableexcludes<span style="color:#f92672">=</span>kubernetes
</span></span><span style="display:flex;"><span>systemctl enable --now kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nerdctl -n k8s.io pull docker.io/calico/cni:v3.24.5
</span></span><span style="display:flex;"><span>nerdctl -n k8s.io pull docker.io/calico/node:v3.24.5
</span></span><span style="display:flex;"><span>nerdctl -n k8s.io pull docker.io/calico/kube-controllers:v3.24.5
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/calico.yaml -O
</span></span></code></pre></div><p>安装好之后，基于这台ECS创建一个自定义镜像，然后将此镜像复制到国内区域。</p>
<h2 id="使用镜像搭建-kubernetes-单节点集群">使用镜像搭建 Kubernetes 单节点集群</h2>
<p>基于上面创建的镜像，在国内的区域也可以很方便地使用 <code>kubeadm</code> 创建新集群，因为所需的工具和镜像都已经准备好了。</p>
<p>下面是创建单节点集群的命令：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>192.168.0.0/16 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --service-cidr<span style="color:#f92672">=</span>10.96.0.0/12 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --kubernetes-version<span style="color:#f92672">=</span>v1.25.4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>/etc/kubernetes/admin.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f calico.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 允许在 master 节点运行普通的业务</span>
</span></span><span style="display:flex;"><span>kubectl taint nodes --all node-role.kubernetes.io/control-plane-
</span></span></code></pre></div><h2 id="使用镜像搭建-kubernetes-多节点集群">使用镜像搭建 Kubernetes 多节点集群</h2>
<p>Kubernetes 多节点集群通常需要部署至少 3 个 <code>master</code> 节点（也叫<code>control plane nodes</code>），需要一个负载均衡的地址来将请求分发到各个 <code>apiserver</code>：</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/d1411cded83856552f37911eb4522d9887ca4e83/b94b2/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg" alt="Stacked etcd topology"></p>
<p>使用阿里云的 <code>PrivateZone</code> 服务，可以比较简单地配置内网的域名。在本次测试中，先配置内网域名 <code>k8smaster.k8s-in</code> 作为控制平面的地址。</p>
<ul>
<li>基于镜像创建第一台 master 节点的服务器，命名为 <code>k8s-master1</code></li>
<li>在 <code>PrivateZone</code> 中添加一条 A 记录，指向 <code>k8s-master1</code> 的内网IP地址</li>
<li>初始化时通过 <code>--upload-certs</code> 参数，将证书存到集群中，后面在添加其他节点时，需要用到证书</li>
</ul>
<p>初始化命令：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm init --control-plane-endpoint<span style="color:#f92672">=</span>k8smaster.k8s-in <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --pod-network-cidr<span style="color:#f92672">=</span>192.168.0.0/16 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --service-cidr<span style="color:#f92672">=</span>10.96.0.0/12 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --kubernetes-version<span style="color:#f92672">=</span>v1.25.4 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --upload-certs
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>/etc/kubernetes/admin.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f calico.yaml
</span></span></code></pre></div><p>初始化的输出内容类似于这样：</p>
<pre tabindex="0"><code>Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join k8smaster.k8s-in:6443 --token xnbtmw.bkb0epe6uiof6g3b \
  --discovery-token-ca-cert-hash sha256:82a830b608bf05f71867a182f5f305bda0c6ee447a1aa32ab9c1cd43af217851 \
  --control-plane --certificate-key c2f2d167ea71319c50a1818750f3b9818ae972a572ca7be48ab370c37b9774c7

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&#34;kubeadm init phase upload-certs --upload-certs&#34; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join k8smaster.k8s-in:6443 --token xnbtmw.bkb0epe6uiof6g3b \
  --discovery-token-ca-cert-hash sha256:82a830b608bf05f71867a182f5f305bda0c6ee447a1aa32ab9c1cd43af217851
</code></pre><p>通过 <code>kubectl get nodes</code> 确认第一个节点的状态是否 Ready：</p>
<pre tabindex="0"><code>NAME          STATUS   ROLES           AGE     VERSION
k8s-master1   Ready    control-plane   21s     v1.25.4
</code></pre><p>基于镜像创建第二台 master 节点的服务器，命名为 <code>k8s-master2</code>，执行加入集群操作。其中 <code>--control-plane</code> 参数表明要以 master 的身份加入集群：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join k8smaster.k8s-in:6443 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --token xnbtmw.bkb0epe6uiof6g3b <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --discovery-token-ca-cert-hash sha256:82a830b608bf05f71867a182f5f305bda0c6ee447a1aa32ab9c1cd43af217851 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --control-plane <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --certificate-key c2f2d167ea71319c50a1818750f3b9818ae972a572ca7be48ab370c37b9774c7
</span></span></code></pre></div><p>通过 <code>kubectl get nodes</code> 确认第二个节点的状态是否 Ready：</p>
<pre tabindex="0"><code>NAME          STATUS   ROLES           AGE     VERSION
k8s-master1   Ready    control-plane   2m57s   v1.25.4
k8s-master2   Ready    control-plane   33s     v1.25.4
</code></pre><p>在 <code>PrivateZone</code> 中添加一条 A 记录，指向 <code>k8s-master2</code> 的内网IP地址。</p>
<p>最后是添加 worker 节点的命令：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join k8smaster.k8s-in:6443 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --token xnbtmw.bkb0epe6uiof6g3b <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --discovery-token-ca-cert-hash sha256:82a830b608bf05f71867a182f5f305bda0c6ee447a1aa32ab9c1cd43af217851
</span></span></code></pre></div><ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://hoverruan.me/" >
    &copy;  HoverR's Blog 2022 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
